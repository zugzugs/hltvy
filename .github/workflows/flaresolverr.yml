name: Automated Data Collection

on:
  push:
    branches: [main]
  workflow_dispatch:
  #schedule:
    #- cron: '0 */6 * * *'   # Every 6 hours for better coverage
    #- cron: '30 8,14,20 * * *'  # Peak betting times (8:30, 14:30, 20:30 UTC)

jobs:
  data-collection:
    runs-on: ubuntu-latest
    timeout-minutes: 305
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt

    - name: Setup Docker
      run: |
        docker pull flaresolverr/flaresolverr:latest
        docker run -d --name flaresolverr-container -p 8191:8191 \
          --restart unless-stopped \
          -e LOG_LEVEL=info \
          flaresolverr/flaresolverr:latest

    - name: Wait for FlareSolverr startup
      run: |
        echo "Waiting for FlareSolverr to be ready..."
        for i in {1..30}; do
          if curl -s http://localhost:8191/v1 > /dev/null; then
            echo "FlareSolverr is ready!"
            break
          fi
          echo "Attempt $i/30: FlareSolverr not ready yet..."
          sleep 2
        done

    - name: Run odds data collection
      run: |
        echo "Starting odds collection..."
        python datagatherer_odds.py
        echo "Odds collection completed"
      continue-on-error: true

    - name: Run results data collection  
      run: |
        echo "Starting results collection..."
        python datagatherer_results.py
        echo "Results collection completed"
        
        # Check if we have results
        if [ -f "results.json" ]; then
          RESULTS_COUNT=$(jq length results.json 2>/dev/null || echo "0")
          echo "Collected results: $RESULTS_COUNT"
          
          # Run recovery helper if results seem problematic
          if [ "$RESULTS_COUNT" -eq "0" ] && [ -f "scrape_state.json" ]; then
            echo "No results found, checking for recovery options..."
            python scripts/recovery_helper.py --auto-fix || true
          fi
        fi
      continue-on-error: true

    - name: Generate data summary
      run: python scripts/generate_summary.py
      continue-on-error: true

    - name: Check for data changes
      id: changes
      run: |
        git add -A
        if git diff --staged --quiet; then
          echo "No changes detected"
          echo "has_changes=false" >> $GITHUB_OUTPUT
        else
          echo "Changes detected"
          echo "has_changes=true" >> $GITHUB_OUTPUT
        fi

    - name: Commit and push changes
      if: steps.changes.outputs.has_changes == 'true'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Create detailed commit message
        TIMESTAMP=$(date -u +"%Y-%m-%d %H:%M:%S UTC")
        ODDS_COUNT=$(jq length upcoming.json 2>/dev/null || echo "0")
        RESULTS_COUNT=$(jq length results.json 2>/dev/null || echo "0")
        
        git commit -m "ðŸ¤– Automated data update - $TIMESTAMP

        ðŸ“Š Data Summary:
        - Upcoming matches with odds: $ODDS_COUNT
        - Historical results: $RESULTS_COUNT
        - Collection time: $TIMESTAMP
        
        ðŸ”„ Auto-generated by GitHub Actions"
        
        git push

    - name: Upload artifacts on failure
      if: failure()
      uses: actions/upload-artifact@v4
      with:
        name: debug-logs-${{ github.run_number }}
        path: |
          *.log
          scrape_state.json
          failed_urls.json
        retention-days: 7

    - name: Cleanup
      if: always()
      run: |
        docker stop flaresolverr-container || true
        docker rm flaresolverr-container || true
